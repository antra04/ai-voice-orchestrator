{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import login\nlogin()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport sys\n\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n                       \"git+https://github.com/huggingface/parler-tts.git\"])\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n                       \"soundfile\", \"fastapi\", \"uvicorn\", \"nest-asyncio\", \"pyngrok\"])\n\nprint(\"Installation complete\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom parler_tts import ParlerTTSForConditionalGeneration\nfrom transformers import AutoTokenizer\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ParlerTTSForConditionalGeneration.from_pretrained(\n    \"ai4bharat/indic-parler-tts\"\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\ndescription_tokenizer = AutoTokenizer.from_pretrained(\n    model.config.text_encoder._name_or_path\n)\n\nprint(\"Model loaded successfully\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastapi import FastAPI, HTTPException\nfrom fastapi.responses import Response\nfrom pydantic import BaseModel\nimport nest_asyncio\nimport uvicorn\nfrom pyngrok import ngrok\nfrom threading import Thread\nimport soundfile as sf\nimport numpy as np\nimport io\n\nnest_asyncio.apply()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastapi import FastAPI, HTTPException\nfrom fastapi.responses import Response\nfrom pydantic import BaseModel\nimport nest_asyncio\nimport uvicorn\nfrom pyngrok import ngrok\nfrom threading import Thread\nimport soundfile as sf\nimport numpy as np\nimport io\n\nnest_asyncio.apply() \n\napp = FastAPI(\n    title=\"Indic TTS API\",\n    description=\"Text-to-speech endpoint for LLM orchestration\",\n    version=\"1.0\"\n)\n\nclass TextInput(BaseModel):\n    text: str\n    description: str = \"Rani speaks in a formal, polished tone with precise pronunciation and professional composure suitable for corporate calls\"\n\n@app.get(\"/\")\ndef root():\n    return {\n        \"status\": \"online\",\n        \"service\": \"Indic TTS API\",\n        \"model\": \"ai4bharat/indic-parler-tts\"\n    }\n\n@app.post(\"/generate-speech\")\ndef generate_speech(input: TextInput):\n    \"\"\"Receives text from LLM and returns audio file\"\"\"\n    try:\n        description = input.description\n        description_lower = description.lower()\n        \n        #  Log gender detection for debugging\n        if any(name in description_lower for name in [\"rohit\", \"aman\", \"jatin\", \"dinesh\", \"thomas\"]):\n            print(f\" Using MALE voice: {description[:60]}...\")\n        else:\n            print(f\" Using FEMALE voice: {description[:60]}...\")\n        \n        #  USE ORIGINAL DESCRIPTION \n        description_input_ids = description_tokenizer(\n            description,\n            return_tensors=\"pt\"\n        ).to(device)\n        \n        prompt_input_ids = tokenizer(\n            input.text,\n            return_tensors=\"pt\"\n        ).to(device)\n        \n        # Generate audio\n        with torch.no_grad():\n            generation = model.generate(\n                input_ids=description_input_ids.input_ids,\n                attention_mask=description_input_ids.attention_mask,\n                prompt_input_ids=prompt_input_ids.input_ids,\n                prompt_attention_mask=prompt_input_ids.attention_mask,\n            )\n        \n        audio_arr = generation.cpu().numpy().squeeze()\n        sample_rate = model.config.sampling_rate\n        \n        # Save to buffer\n        buffer = io.BytesIO()\n        sf.write(buffer, audio_arr, sample_rate, format=\"WAV\")\n        buffer.seek(0)\n        \n        return Response(\n            content=buffer.read(),\n            media_type=\"audio/wav\",\n            headers={\"Content-Disposition\": \"attachment; filename=speech.wav\"}\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Speech generation failed: {str(e)}\")\n\n@app.get(\"/health\")\ndef health_check():\n    return {\n        \"status\": \"healthy\",\n        \"gpu_available\": torch.cuda.is_available(),\n        \"device\": device\n    }\n\nprint(\" FastAPI application created - using original voice descriptions\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import getpass\n\nngrok_token = getpass.getpass(\"Token\")\nngrok.set_auth_token(ngrok_token)\n\npublic_url = ngrok.connect(8000)\n\nprint(\"TTS API is now live\")\nprint(f\"Public URL: {public_url}\")\nprint(f\"API Documentation: {public_url}/docs\")\nprint(f\"Health Check: {public_url}/health\")\nprint(\"\\nEndpoint for LLM:\")\nprint(f\"POST {public_url}/generate-speech\")\nprint('Request body: {\"text\": \"your text here\"}')\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_server():\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8000,\n        log_level=\"info\"\n    )\n\nserver_thread = Thread(target=run_server, daemon=True)\nserver_thread.start()\n\nprint(\"Server is running\")\nprint(\"API is accessible via the ngrok URL above\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}